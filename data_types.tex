\section{Data Types}
\subsection{Introduction to Data Types}
A data type is a construct in programming that defines what kind of data a
variable can hold and the operations that a programmer can do with this type.
For those who are familiar with programming, integers, floating point numbers,
booleans and strings come to mind. If these names are unfamiliar, consider the
following code example in Python:
\begin{verbatim}
    is_a_math_paper: bool = True
    topic: str = "Obfuscation"
\end{verbatim}
In the above example, we have a variable \textit{is\_a\_math\_paper} that is a
boolean type. It can therefore hold only the Python values \textit{True} and
\textit{False}. The other variable \textit{topic} is of type \textit{str},
which is the data
type for text. Of course, we can represent much more than
these primitive types by creating a new type and defining its basic
operations. We may for example represent a polynomial and define the addition
of two polynomials as adding the coefficients of the corresponding
same degree variable. There are endless possibilities to represent data in
most programming languages.

The discussion of data types is important as creating new types, changing
between them, and using different operations for the same type is one common
method used in code obfuscation. For example, instead of working with a boolean
$ B $ to check a condition, we can use two integers $ p $ and $ q $, both of
which we can manipulate using integer arithmetic. Hence, wherever we use $ B $,
we may now, for example, add the values of $ p $ and $ q $ and if the sum is
even, that would be equivalent to $ B $ being true.

\subsection{Representing Data Types and Their Operations as Matrices}
One method of obfuscation that we can employ is the use of matrices to obscure
data types and their operations. One example would be to represent a
rational number, what would often be a floating point number in programs, as a
matrix.

Let us say we have a variable $ x $, a rational number, that we wish to
represent as a matrix $ A $. We represent this relation as $ x \rightsquigarrow
A $, which means that $ x $ is obfuscated by $ A $. At this point, we need to
define two functions that will help us move between the data type and the
obfuscation.

Our first function is called the abstraction function denoted by $ af: D \to E
$ and is
defined as follows:
\begin{equation*}
    x \rightsquigarrow A \Leftrightarrow x = af (A)
\end{equation*}
Our abstraction function will allow us to retrieve the original value of our
data type using the obfuscation that we have created, in this case $ A $. The
abstraction function is surjective, as there could be several possible
obfuscations that represent the same value. This characteristic allows for less
predictability in the generated code and thus creates less identifiable
patterns that could help someone reverse engineer an application.

Our second function is called the conversion function denoted by $ cf: E \to D
$ and is defined as follows:
\begin{equation*}
    cf (n) = A
\end{equation*}
Our conversion function will take $ x $, what we want to obfuscate, as an input
and output the obfuscation $ A $. This function is the inverse of $ af $.

Now back to the realm of matrices, we need to define our aforementioned
functions. One example would be to have $ cf $ generate an $ A $ such that $ af
$ simply calculates the determinant of $ A $ yielding $ x $. Thus, we may for
example define $ cf $ as follows
\begin{equation*}
    cf(x)
    =
    \begin{bmatrix}
        x & a \\
        0 & 1
    \end{bmatrix}
\end{equation*}
While the above is our mathematical definition of the $ cf $ function, we can
also define it in Python using the scientific library NumPy, which allows us to
easily represent matrices in code:
\begin{verbatim}
    from random import randint
    from numpy import array

    def cf(x: int) -> np.array:
        # Generate a random integer between 0 and a 1000
        a: int = randint(0, 1000)
        return array([[x, a],
                      [0, 1]])
\end{verbatim}
This function is equivalent to the mathematical definition that precedes it and
is representing a matrix using NumPy's data type \textit{array}, which allows
us to
create an array of arrays, each representing a row in our desired matrix. Note
that in this example, there are no restrictions on what $ a $ can be. In our
Python code specifically, $ a $ will be a random number generated for us that
is between $ 0
$ and $ 1000 $. Now, the abstraction
function would simply be
\begin{equation*}
    af \left(
    \begin{bmatrix}
        a & b \\
        c & d
    \end{bmatrix}
    \right)
    =
    \det
    \begin{bmatrix}
        a & b \\
        c & d
    \end{bmatrix}
    = ad - bc
\end{equation*}
In Python:
\begin{verbatim}
    def af(A: np.array) -> int:
        x = linalg.det(A) # Calculate the determinant
        return x          # Return the calculated value
\end{verbatim}
We can now test our 2 functions
\begin{equation*}
    af(cf(x)) = x \cdot 1- a \cdot 0 = x
\end{equation*}
It works! This is not enough, however, as we still need to define operations
that correspond to basic arithmetic. Let us take addition as an
example. We need a function \textbf{plus} such that
\begin{equation*}
    x + y \rightsquigarrow \mathbf{plus(A, B)} : x \rightsquigarrow A, y
    \rightsquigarrow B
\end{equation*}
\textbf{plus} can then be defined as
\begin{equation*}
    plus\left(
    \begin{bmatrix}
        x & a \\
        0 & 1
    \end{bmatrix},
    \begin{bmatrix}
        y & b \\
        0 & 1
    \end{bmatrix}
    \right)
    =
    \begin{bmatrix}
        x + y & a + b \\
        0     & 1
    \end{bmatrix}
\end{equation*}
Translating our math to code:
\begin{verbatim}
    def plus(A: np.array, B: np.array) -> np.array:
        x_11: int = A.item(0, 0) + B.item(0, 0)
        x_12: int = A.item(0, 1) + B.item(0, 1)
        return array([[x_11, x_12],
                      [   0,    1]])
\end{verbatim}
In programming in general, we start counting at 0 instead of 1. Hence, when we
write \textit{A.item(0, 0)}, we want the element in the first row and first
column
of
$ A $. \textit{A.item(0, 1)} is thus the element in the first row and second
column. In the spirit of our plus function, we also define a \textbf{times}
function:
\begin{equation*}
   times\left(
   \begin{bmatrix}
       x & a \\
       0 & 1
   \end{bmatrix},
   \begin{bmatrix}
       y & b \\
       0 & 1
   \end{bmatrix}
   \right)
   =
   \begin{bmatrix}
       1 & a  \cdot b \\
       0     & x \cdot y
   \end{bmatrix}
\end{equation*}
The equivalent Python code:
\begin{verbatim}
    def times(A: np.array, B: np.array) -> np.array:
        x_12: int = A.item(0, 1) * B.item(0, 1)
        x_22: int = A.item(1, 1) * B.item(1, 1)
        return array([[1, x_12],
                      [0, x_22]])
\end{verbatim}
Notice that the matrix output of this function has a slightly different
configuration than that of the plus function. The elements have shifted places.
The key takeaway here is that you can define these functions in any way you
want as long as when you take the determinant, you get the correct output:
$ x \cdot y $.

We can define many more operations beyond addition and multiplication such as
division, subtraction, negation, exponentiation, etc. It is important for
these operations to be defined for our matrices to make our obfuscated code
harder to reverse engineer. It would not be much use to simply represent
numbers as
matrices and then convert them back whenever we want to perform arithmetic or
other operations. Moreover, the way we define each operation should also be
sufficiently complex. It is worth noting, though, that these operations need
not be defined in the same way normal matrix operations like addition,
multiplication, etc., are defined. The programmer has complete control over
these definitions as long as they can prove that they will yield the desired
output wherever they are used.

It is therefore worth noting that the example above, although not to be taken
lightly, is too simple an
obfuscation to be used in the real world. It does, however, give a very good
sense of how
obfuscation works. A better example, as proposed by Drape et al., would be to
have $ n $ be an eigenvector of a $ 2 \times 2 $ matrix. We would then fix the
second eigenvalue and define a more robust conversion function that is harder
to decipher. If we wish to make our obfuscation even stronger, we can make our
matrix bigger for example.



